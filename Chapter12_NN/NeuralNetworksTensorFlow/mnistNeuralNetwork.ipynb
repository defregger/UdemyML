{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.losses import *\n",
    "from tensorflow.keras.utils import *\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "\n",
    "x = dataset.data\n",
    "y = dataset.target\n",
    "y = to_categorical(y, num_classes=10)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=x.shape[1])) # Input Layer (64 Neurons) to first Hidden Layer (512 Neurons)\n",
    "model.add(Activation(\"relu\")) # max(0, value)\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(y.shape[1])) # Last Hidden Layer (256 Neurons) to Output Layer (10 Neurons)\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "35/43 [=======================>......] - ETA: 0s - loss: 0.1880 - accuracy: 0.9741WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "43/43 [==============================] - 0s 6ms/step - loss: 0.1872 - accuracy: 0.9718 - val_loss: 0.2600 - val_accuracy: 0.9422\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9703 - val_loss: 0.2341 - val_accuracy: 0.9444\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1721 - accuracy: 0.9748 - val_loss: 0.2265 - val_accuracy: 0.9511\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9740 - val_loss: 0.2330 - val_accuracy: 0.9467\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9755 - val_loss: 0.2125 - val_accuracy: 0.9578\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9777 - val_loss: 0.2117 - val_accuracy: 0.9578\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9777 - val_loss: 0.2028 - val_accuracy: 0.9578\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1441 - accuracy: 0.9762 - val_loss: 0.1998 - val_accuracy: 0.9578\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1396 - accuracy: 0.9792 - val_loss: 0.1945 - val_accuracy: 0.9622\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9792 - val_loss: 0.1988 - val_accuracy: 0.9622\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1322 - accuracy: 0.9800 - val_loss: 0.1915 - val_accuracy: 0.9667\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1285 - accuracy: 0.9807 - val_loss: 0.1890 - val_accuracy: 0.9622\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9792 - val_loss: 0.1837 - val_accuracy: 0.9644\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9837 - val_loss: 0.1832 - val_accuracy: 0.9622\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9837 - val_loss: 0.1793 - val_accuracy: 0.9644\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.9829 - val_loss: 0.1761 - val_accuracy: 0.9667\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9844 - val_loss: 0.1751 - val_accuracy: 0.9711\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9852 - val_loss: 0.1732 - val_accuracy: 0.9689\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9859 - val_loss: 0.1737 - val_accuracy: 0.9711\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9822 - val_loss: 0.1691 - val_accuracy: 0.9711\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9852 - val_loss: 0.1652 - val_accuracy: 0.9711\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9866 - val_loss: 0.1652 - val_accuracy: 0.9711\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9866 - val_loss: 0.1621 - val_accuracy: 0.9667\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.9852 - val_loss: 0.1594 - val_accuracy: 0.9711\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0968 - accuracy: 0.9881 - val_loss: 0.1578 - val_accuracy: 0.9667\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0950 - accuracy: 0.9859 - val_loss: 0.1563 - val_accuracy: 0.9733\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9881 - val_loss: 0.1571 - val_accuracy: 0.9689\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0913 - accuracy: 0.9866 - val_loss: 0.1544 - val_accuracy: 0.9733\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.0899 - accuracy: 0.9881 - val_loss: 0.1538 - val_accuracy: 0.9711\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9852 - val_loss: 0.1519 - val_accuracy: 0.9689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25fc96a7400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGD(lr=0.0005)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "model.fit(x=x_train, y=y_train, epochs=30, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
