{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_digits()\n",
    "\n",
    "x = dataset.data\n",
    "y = dataset.target\n",
    "y = to_categorical(y, num_classes=10)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=x.shape[1])) # Input Layer (64 Neurons) to first Hidden Layer (512 Neurons)\n",
    "model.add(Activation(\"relu\")) # max(0, value)\n",
    "model.add(Dense(512))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(y.shape[1])) # Last Hidden Layer (256 Neurons) to Output Layer (10 Neurons)\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 10ms/step - loss: 2.3113 - accuracy: 0.2710 - val_loss: 1.6394 - val_accuracy: 0.4667\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2273 - accuracy: 0.6466 - val_loss: 1.1202 - val_accuracy: 0.6422\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8195 - accuracy: 0.7840 - val_loss: 0.7881 - val_accuracy: 0.7889\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.8471 - val_loss: 0.6275 - val_accuracy: 0.8289\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8827 - val_loss: 0.5447 - val_accuracy: 0.8578\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8946 - val_loss: 0.4710 - val_accuracy: 0.8778\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.9117 - val_loss: 0.4210 - val_accuracy: 0.8889\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.9250 - val_loss: 0.3857 - val_accuracy: 0.8978\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.9310 - val_loss: 0.3635 - val_accuracy: 0.9044\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2870 - accuracy: 0.9391 - val_loss: 0.3344 - val_accuracy: 0.9067\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.9391 - val_loss: 0.3264 - val_accuracy: 0.9156\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.9428 - val_loss: 0.2991 - val_accuracy: 0.9200\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.9488 - val_loss: 0.2863 - val_accuracy: 0.9244\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9495 - val_loss: 0.2677 - val_accuracy: 0.9311\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2113 - accuracy: 0.9562 - val_loss: 0.2580 - val_accuracy: 0.9289\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.2013 - accuracy: 0.9584 - val_loss: 0.2496 - val_accuracy: 0.9289\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1930 - accuracy: 0.9607 - val_loss: 0.2438 - val_accuracy: 0.9400\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1864 - accuracy: 0.9673 - val_loss: 0.2337 - val_accuracy: 0.9311\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9659 - val_loss: 0.2247 - val_accuracy: 0.9356\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1714 - accuracy: 0.9673 - val_loss: 0.2289 - val_accuracy: 0.9356\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1654 - accuracy: 0.9703 - val_loss: 0.2168 - val_accuracy: 0.9400\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1602 - accuracy: 0.9725 - val_loss: 0.2115 - val_accuracy: 0.9422\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.9733 - val_loss: 0.2158 - val_accuracy: 0.9400\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1517 - accuracy: 0.9733 - val_loss: 0.1984 - val_accuracy: 0.9444\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1458 - accuracy: 0.9748 - val_loss: 0.1932 - val_accuracy: 0.9467\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1415 - accuracy: 0.9770 - val_loss: 0.1886 - val_accuracy: 0.9489\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9785 - val_loss: 0.1834 - val_accuracy: 0.9489\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.9785 - val_loss: 0.1858 - val_accuracy: 0.9533\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9807 - val_loss: 0.1767 - val_accuracy: 0.9622\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9807 - val_loss: 0.1760 - val_accuracy: 0.9578\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23714c9c1c0>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=SGD(lr=0.0005),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    epochs=30,\n",
    "    validation_data=(x_test, y_test)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}